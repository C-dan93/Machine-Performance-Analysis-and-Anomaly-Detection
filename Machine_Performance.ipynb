{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COA7YRqMB0I2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv(r\"sample_interview_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the 'UID' column from the DataFrame\n",
        "#data.drop(columns=['UID'], inplace=True)\n",
        "\n",
        "# Fill missing values with median\n",
        "median_speed = data[\"Rotational speed [rpm]\"].median()\n",
        "data[\"Rotational speed [rpm]\"].fillna(median_speed, inplace=True)\n",
        "\n",
        "# Save the modified DataFrame to a CSV file\n",
        "data.to_csv('clean.csv', index=False)\n"
      ],
      "metadata": {
        "id": "-tMogHvHwTan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "Ey1cyv0UvC35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique failure types\n",
        "unique_failure_types = data[\"Failure Type\"].unique()\n",
        "print(unique_failure_types)\n",
        "\n",
        "# Create an empty dictionary to store DataFrames for each failure type\n",
        "failure_type_dataframes = {}\n",
        "\n",
        "# Iterate over unique failure types\n",
        "for failure_type in unique_failure_types:\n",
        "    # Filter the original DataFrame for the current failure type\n",
        "    failure_type_df = data[data[\"Failure Type\"] == failure_type].copy()\n",
        "\n",
        "    # Store the filtered DataFrame in the dictionary\n",
        "    failure_type_dataframes[failure_type] = failure_type_df\n",
        "\n",
        "power_failure = failure_type_dataframes[\"Power Failure\"]\n",
        "Error = failure_type_dataframes[\"Error\"]\n",
        "Tool_Wear_Failure = failure_type_dataframes[\"Tool Wear Failure\"]\n",
        "Overstrain_Failure = failure_type_dataframes[\"Overstrain Failure\"]\n",
        "Random_Failures = failure_type_dataframes[\"Random Failures\"]\n",
        "Heat_Dissipation_Failure = failure_type_dataframes[\"Heat Dissipation Failure\"]\n",
        "# Access the DataFrame for each failure type using the failure type as key\n",
        "# For example, to access the DataFrame for failure type \"Type1\":\n",
        "# type1_df = failure_type_dataframes[\"Type1\"]\n"
      ],
      "metadata": {
        "id": "f9nsjyXtgjOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get unique machine types and failure types\n",
        "unique_machine_types = data['Machine Type'].unique()\n",
        "unique_failure_types = data['Failure Type'].unique()\n",
        "\n",
        "# Create an empty DataFrame with machine types as index and failure types as columns\n",
        "failure_table_counts = pd.DataFrame(index=unique_machine_types, columns=unique_failure_types)\n",
        "\n",
        "# Loop through unique machine types and failure types to fill in the counts\n",
        "for machine_type in unique_machine_types:\n",
        "    for failure_type in unique_failure_types:\n",
        "        count = len(data[(data['Machine Type'] == machine_type) & (data['Failure Type'] == failure_type)])\n",
        "        failure_table_counts.loc[machine_type, failure_type] = count\n",
        "\n",
        "# Print the table\n",
        "failure_table_counts.head(1)\n"
      ],
      "metadata": {
        "id": "HvRRXGs3iNs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df_failure, df_power_failure, df_error, df_tool_wear_failure,\n",
        "# df_overstrain_failure, df_random_failures, df_heat_dissipation_failure are your dataframes\n",
        "\n",
        "# Calculate the number of rows in each dataframe\n",
        "counts = [\n",
        "    len(power_failure),\n",
        "    len(Tool_Wear_Failure),\n",
        "    len(Overstrain_Failure),\n",
        "    len(Random_Failures),\n",
        "    len(Heat_Dissipation_Failure)\n",
        "]\n",
        "\n",
        "# Labels for the pie chart\n",
        "labels = ['Power Failure', 'Tool Wear Failure',\n",
        "          'Overstrain Failure', 'Random Failures', 'Heat Dissipation Failure']\n",
        "\n",
        "# Create the pie chart\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=140)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.title('Proportions of Different Error Types', pad=20)  # Add padding to the title\n",
        "\n",
        "# Add a legend and shift it to the right with some padding\n",
        "plt.legend(labels, loc=\"center left\", bbox_to_anchor=(1, 0.5), title=\"Error Types\", title_fontsize='medium')\n",
        "plt.subplots_adjust(right=0.7)  # Adjust the layout to create a gap between the pie chart and legend\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3_ez1NKchPFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DataFrame to numeric values\n",
        "failure_table_counts_numeric = failure_table_counts.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check for NaN or non-numeric values after conversion\n",
        "print(failure_table_counts_numeric.isnull().sum())\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(failure_table_counts_numeric, annot=True, fmt='d', cmap='YlGnBu', linewidths=0.5, linecolor='black', cbar=True)\n",
        "plt.xlabel('Failure Types', fontsize=12)\n",
        "plt.ylabel('Machine Types', fontsize=12)\n",
        "plt.title('Distribution of Failure Counts', fontsize=14)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x_ZZNZCKpY7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate percentages excluding \"No Failure\" category\n",
        "#failure_table_percentages = failure_table_counts.drop(columns=['No Failure']).div(failure_table_counts.drop(columns=['No Failure']).sum(axis=1), axis=0) * 100\n",
        "failure_table_counts_without_error = failure_table_counts.drop(columns=['No Failure', 'Error'])\n",
        "failure_table_percentages = failure_table_counts_without_error.div(failure_table_counts_without_error.sum(axis=1), axis=0) * 100\n",
        "\n",
        "# Plot percentage stacked bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "failure_table_percentages.plot(kind='bar', stacked=True, cmap=\"YlGnBu\")\n",
        "plt.title('Percentage of Failure Types for Each Machine Type (Excluding \"Error\")')\n",
        "plt.xlabel('Machine Type')\n",
        "plt.ylabel('Percentage')\n",
        "plt.legend(title='Failure Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Q385iTUntibS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***MACHINE AVAILABILITY INDEX***"
      ],
      "metadata": {
        "id": "266PZXq0-HRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load or define the 'data' DataFrame before executing this code\n",
        "\n",
        "# Convert 'Timestamp' column to datetime\n",
        "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
        "\n",
        "# Calculate time differences between consecutive timestamps for each machine type\n",
        "data['Time Delta'] = data.groupby('Machine Type')['Timestamp'].diff()\n",
        "\n",
        "# Handle missing values in 'Time Delta' (e.g., for the first row of each machine type)\n",
        "data['Time Delta'] = data['Time Delta'].fillna(pd.Timedelta(seconds=0))\n",
        "\n",
        "# Group by 'Machine Type' and sum 'Time Delta' to get total operating time for each machine type\n",
        "total_operating_time = data.groupby('Machine Type')['Time Delta'].sum()\n",
        "\n",
        "# Filter the DataFrame to include rows where Failure Type is not 'No Failure' or 'Error'\n",
        "failures_df = data[~data['Failure Type'].isin(['No Failure', 'Error'])]\n",
        "\n",
        "# Calculate failure counts for each machine type\n",
        "failure_counts = failures_df.groupby('Machine Type').size()\n",
        "\n",
        "# Convert failure counts to hours (assuming 1 failure = 1 hour)\n",
        "failure_counts_hours = failure_counts.astype('timedelta64[h]')\n",
        "\n",
        "# Calculate machine availability index for each machine type\n",
        "machine_availability_index = (total_operating_time - failure_counts_hours) / total_operating_time * 100\n",
        "\n",
        "# Handle division by zero errors (e.g., when total operating time is zero)\n",
        "machine_availability_index = machine_availability_index.fillna(100)  # Assume availability is 100% if no operating time recorded\n",
        "\n",
        "# Plot the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(machine_availability_index.index, machine_availability_index, color='skyblue')\n",
        "\n",
        "# Add hover values to the bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.gca().text(bar.get_x() + bar.get_width() / 2, height * 1.01, f'{height:.2f}%', ha='center', color='black', fontsize=8)\n",
        "\n",
        "plt.title('Machine Availability Index by Machine Type')\n",
        "plt.xlabel('Machine Type')\n",
        "plt.ylabel('Availability Index (%)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "m8VkLW0uvGKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate failure rate (failures per hour) for each machine type\n",
        "failure_rate = failure_counts / total_operating_time_hours\n",
        "\n",
        "# Print the failure rate for each machine type\n",
        "print(\"Failure Rate (failures per hour) by Machine Type:\")\n",
        "print(failure_rate)\n"
      ],
      "metadata": {
        "id": "R0jiS0z3-d9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADDING MORE FEATURES"
      ],
      "metadata": {
        "id": "ouckS5LBvEJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your DataFrame with observations\n",
        "original_data = data.copy()  # Make a copy of the original data\n",
        "\n",
        "# Convert 'Timestamp' column to datetime\n",
        "original_data['Timestamp'] = pd.to_datetime(original_data['Timestamp'])\n",
        "\n",
        "# Calculate total operating time and total failures for each machine type\n",
        "original_data['Total Operating Time'] = original_data.groupby('Machine Type')['Timestamp'].diff().dt.total_seconds() / 3600\n",
        "\n",
        "# Exclude specified types of failures and count them\n",
        "specified_failures = ['Power Failure', 'Tool Wear Failure', 'Overstrain Failure', 'Random Failures', 'Heat Dissipation Failure']\n",
        "original_data['Total Failures'] = original_data['Failure Type'].isin(specified_failures).astype(int)\n",
        "\n",
        "# Calculate machine availability index for each observation\n",
        "original_data['Machine Availability Index (%)'] = ((original_data['Total Operating Time'] - original_data['Total Failures']) / original_data['Total Operating Time']) * 100\n",
        "\n",
        "# Calculate failure rate for each observation\n",
        "original_data['Failure Rate (failures per hour)'] = original_data['Total Failures'] / original_data['Total Operating Time']\n",
        "\n",
        "# Filter the DataFrame to show only rows where Failure Type is not 'No Failure' and is any of the specified types of failures\n",
        "specified_failures = ['Power Failure', 'Tool Wear Failure', 'Overstrain Failure', 'Random Failures', 'Heat Dissipation Failure']\n",
        "failures_df = original_data[original_data['Failure Type'].isin(specified_failures)]\n",
        "\n",
        "# Display the first 5 rows of the filtered DataFrame\n",
        "failures_df.head(5)\n"
      ],
      "metadata": {
        "id": "vtx8xVDTrq5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert 'Timestamp' to datetime if it's not already in datetime format\n",
        "original_data['Timestamp'] = pd.to_datetime(original_data['Timestamp'])\n",
        "\n",
        "# Extract year, month, and day from 'Timestamp' and create new columns\n",
        "original_data['Year'] = original_data['Timestamp'].dt.year\n",
        "original_data['Month'] = original_data['Timestamp'].dt.month\n",
        "original_data['Day'] = original_data['Timestamp'].dt.day\n",
        "\n",
        "# Filter the data for the year 2002\n",
        "year_2002_data = original_data[original_data['Year'] == 2002]\n",
        "\n",
        "# Filter the data for the years 2001 and 2003\n",
        "years_2001_2003_data = original_data[(original_data['Year'] == 2001) | (original_data['Year'] == 2003)]\n",
        "\n",
        "# Create the plot for 2002 alone\n",
        "plt.figure(figsize=(10, 6))  # Set the figure size\n",
        "\n",
        "# Plot availability rate over time for 2002\n",
        "sns.lineplot(x='Month', y='Machine Availability Index (%)', data=year_2002_data, ci=None)\n",
        "\n",
        "# Set plot title and labels\n",
        "plt.title('Availability Rates Over Time (Year 2002)')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Availability Rate (%)')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
        "plt.show()\n",
        "\n",
        "# Create the plot for 2001 and 2003 combined\n",
        "plt.figure(figsize=(10, 6))  # Set the figure size\n",
        "\n",
        "# Plot availability rate over time for 2001 and 2003 combined\n",
        "sns.lineplot(x='Day', y='Machine Availability Index (%)', hue='Year', data=years_2001_2003_data, ci=None)\n",
        "\n",
        "# Set plot title and labels\n",
        "plt.title('Availability Rates Over Time (Years 2001 & 2003)')\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Availability Rate (%)')\n",
        "\n",
        "# Add legend\n",
        "plt.legend(title='Year', loc='upper right')\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Wp95Xt_3vfE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VISUALS**"
      ],
      "metadata": {
        "id": "OJRsEkhkjLFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "# Define failure type groups\n",
        "grouped_failure_types = {\n",
        "    'Tool Wear and Overstrain Failure': ['Tool Wear Failure', 'Overstrain Failure'],\n",
        "    'Power Failure and Random Failure': ['Power Failure', 'Random Failures'],\n",
        "    'Heat Dissipation Failure': ['Heat Dissipation Failure']\n",
        "}\n",
        "\n",
        "# Filter the data for the year 2002\n",
        "year_2002_data = data[data['Year'] == 2002]\n",
        "\n",
        "# Plot time series for each group of failure types\n",
        "for group_name, failure_types in grouped_failure_types.items():\n",
        "    # Filter data for the current group of failure types\n",
        "    group_data = year_2002_data[year_2002_data['Failure Type'].isin(failure_types)]\n",
        "\n",
        "    # Plot time series\n",
        "    plt.figure(figsize=(10, 6))  # Set the figure size\n",
        "    sns.lineplot(x='Month', y='Failure Rate (failures per hour)', hue='Failure Type', data=group_data, ci=None)\n",
        "\n",
        "    # Set plot title and labels\n",
        "    plt.title(f'Failure Rates Over Time - {group_name}')\n",
        "    plt.xlabel('Month')\n",
        "    plt.ylabel('Failure Rate (failures per hour)')\n",
        "\n",
        "    # Add legend\n",
        "    plt.legend(title='Failure Type', loc='upper right')\n",
        "\n",
        "    # Show plot\n",
        "    plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "8NAEEaPVlKi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert 'Timestamp' to datetime if it's not already in datetime format\n",
        "original_data['Timestamp'] = pd.to_datetime(original_data['Timestamp'])\n",
        "\n",
        "# Extract year, month, and day from 'Timestamp' and create new columns\n",
        "original_data['Year'] = original_data['Timestamp'].dt.year\n",
        "original_data['Month'] = original_data['Timestamp'].dt.month\n",
        "original_data['Day'] = original_data['Timestamp'].dt.day\n",
        "\n",
        "# Calculate total operating time for each observation\n",
        "original_data['Total Operating Time'] = original_data.groupby('Machine Type')['Timestamp'].diff().dt.total_seconds() / 3600\n",
        "\n",
        "# Calculate the number of failures for each observation\n",
        "original_data['Number of Failures'] = (original_data['Failure Type'] != 'No Failure').astype(int)\n",
        "\n",
        "# Calculate failure rate (failures per hour) for each observation\n",
        "original_data['Failure Rate (failures per hour)'] = original_data['Number of Failures'] / original_data['Total Operating Time']\n",
        "\n",
        "# Filter data for the year 2002\n",
        "year_2002_data = original_data[original_data['Year'] == 2002]\n",
        "\n",
        "# Filter data for the year 2001\n",
        "year_2001_data = original_data[original_data['Year'] == 2001]\n",
        "\n",
        "# Filter data for the year 2003\n",
        "year_2003_data = original_data[original_data['Year'] == 2003]\n",
        "\n",
        "# Create a plot for the year 2002 by months\n",
        "plt.figure(figsize=(10, 6))  # Set the figure size\n",
        "sns.barplot(x='Month', y='Failure Rate (failures per hour)', data=year_2002_data, ci=None)\n",
        "plt.title('Failure Rate Over Months (Year 2002)')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Failure Rate (failures per hour)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create a plot for the year 2001 by days\n",
        "plt.figure(figsize=(10, 6))  # Set the figure size\n",
        "sns.barplot(x='Day', y='Failure Rate (failures per hour)', data=year_2001_data, ci=None)\n",
        "plt.title('Failure Rate Over Days (Year 2001)')\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Failure Rate (failures per hour)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create a plot for the year 2003 by days\n",
        "plt.figure(figsize=(10, 6))  # Set the figure size\n",
        "sns.barplot(x='Day', y='Failure Rate (failures per hour)', data=year_2003_data, ci=None)\n",
        "plt.title('Failure Rate Over Days (Year 2003)')\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Failure Rate (failures per hour)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WFAdlpWVqUcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total occurrences of each unique machine type\n",
        "total_machine_type_counts = data[\"Machine Type\"].value_counts()\n",
        "total_machine_type_counts"
      ],
      "metadata": {
        "id": "i6g4zqJeg_oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Count the occurrences of failure for each unique machine type\n",
        "failure_counts = data[data[\"Failure Type\"] != \"No Failure\"][\"Machine Type\"].value_counts()\n",
        "\n",
        "# Calculate the percentage of failures for each unique machine type\n",
        "failure_percentages = (failure_counts / total_machine_type_counts) * 100\n",
        "\n",
        "print(\"Percentage of failures for each unique Machine Type:\")\n",
        "print(failure_percentages)\n",
        "\n"
      ],
      "metadata": {
        "id": "J2wyVylTekMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "failure_type_df"
      ],
      "metadata": {
        "id": "NfSCASIU_4ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of failure types\n",
        "failure_types = [\"Error\", \"Tool Wear Failure\", \"Overstrain Failure\", \"Random Failures\", \"Heat Dissipation Failure\"]\n",
        "\n",
        "# List to store DataFrames for each failure type\n",
        "failure_dfs = []\n",
        "\n",
        "# Iterate over failure types and retrieve the corresponding DataFrame from the dictionary\n",
        "for failure_type in failure_types:\n",
        "    failure_dfs.append(failure_type_dataframes[failure_type])\n",
        "\n",
        "# Concatenate the DataFrames along the rows\n",
        "result_df = pd.concat(failure_dfs)\n",
        "\n",
        "# Get the unique values in the \"Machine Type\" column of the concatenated DataFrame\n",
        "unique_machine_types = result_df[\"Machine Type\"].unique()\n",
        "\n",
        "print(\"Unique Machine Types:\")\n",
        "print(unique_machine_types)\n",
        "\n",
        "# Count the occurrences of each unique machine type\n",
        "machine_type_counts = result_df[\"Machine Type\"].value_counts()\n",
        "\n",
        "print(\"Number of occurrences for each unique Machine Type:\")\n",
        "print(machine_type_counts)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dQwbMPPbxU84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your data is stored in a DataFrame called df\n",
        "# Selecting the relevant columns for correlation analysis\n",
        "selected_columns = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
        "\n",
        "# Creating a new DataFrame with only the selected columns\n",
        "selected_data = data[selected_columns]\n",
        "\n",
        "# Calculating the correlation matrix\n",
        "correlation_matrix = selected_data.corr()\n",
        "\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "id": "sK5Db0AMpbl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your data is stored in a DataFrame called df\n",
        "\n",
        "# Filter data where Target is 0\n",
        "data_target_0 = data[data['Target'] == 0]\n",
        "\n",
        "# Filter data where Target is 1\n",
        "data_target_1 = data[data['Target'] == 1]\n",
        "\n",
        "# Selecting the relevant columns for correlation analysis\n",
        "selected_columns = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
        "\n",
        "# Creating correlation matrices for Target = 0 and Target = 1\n",
        "correlation_matrix_target_0 = data_target_0[selected_columns].corr()\n",
        "correlation_matrix_target_1 = data_target_1[selected_columns].corr()\n",
        "\n",
        "print(\"Correlation Matrix for Target = 0:\")\n",
        "print(correlation_matrix_target_0)\n",
        "\n",
        "print(\"\\nCorrelation Matrix for Target = 1:\")\n",
        "print(correlation_matrix_target_1)\n"
      ],
      "metadata": {
        "id": "r4f51goBaWxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named 'data'\n",
        "# Filter data for Machine Type 'x_1'\n",
        "machine_x1_data = data[data['Machine Type'] == 'x_1']\n",
        "\n",
        "# Group data by 'Failure Type'\n",
        "grouped_by_failure = machine_x1_data.groupby('Failure Type')\n",
        "\n",
        "# Extract data for reference groups ('No Failure' and 'Error')\n",
        "reference_groups = ['No Failure', 'Error']\n",
        "reference_data = grouped_by_failure.get_group(reference_groups[0])\n",
        "for group in reference_groups[1:]:\n",
        "    reference_data = reference_data.append(grouped_by_failure.get_group(group))\n",
        "\n",
        "# Selecting the relevant features\n",
        "features_of_interest = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
        "\n",
        "# Initialize a dictionary to store differences for each failure type\n",
        "failure_differences = {}\n",
        "\n",
        "# Loop through each failure type and calculate the differences\n",
        "for failure_type, failure_data in grouped_by_failure:\n",
        "    if failure_type not in reference_groups:\n",
        "        # Calculate the differences between reference groups and the current failure type for selected features\n",
        "        differences = failure_data[features_of_interest].mean() - reference_data[features_of_interest].mean()\n",
        "        # Store the differences in the dictionary\n",
        "        failure_differences[failure_type] = differences\n",
        "\n",
        "# Display the differences for each failure type\n",
        "for failure_type, differences in failure_differences.items():\n",
        "    print(f\"Differences for {failure_type}:\")\n",
        "    print(differences)\n",
        "    print()  # Add a blank line for readability\n"
      ],
      "metadata": {
        "id": "6Wa2vqH9-4wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# New mean differences for each failure type\n",
        "new_mean_diff_by_failure_type1 = {\n",
        "    'Heat Dissipation Failure': {\n",
        "        'Rotational speed [rpm]': -205.548213,\n",
        "        'Torque [Nm]': 13.796367,\n",
        "        'Tool wear [min]': -1.282956\n",
        "    },\n",
        "    'Overstrain Failure': {\n",
        "        'Rotational speed [rpm]': -185.759971,\n",
        "        'Torque [Nm]': 17.399563,\n",
        "        'Tool wear [min]': 101.382189\n",
        "    },\n",
        "    'Power Failure': {\n",
        "        'Rotational speed [rpm]': 244.579661,\n",
        "        'Torque [Nm]': 12.251734,\n",
        "        'Tool wear [min]': -6.371468\n",
        "    },\n",
        "    'Random Failures': {\n",
        "        'Rotational speed [rpm]': -55.188365,\n",
        "        'Torque [Nm]': 29.356973,\n",
        "        'Tool wear [min]': 33.272600\n",
        "    },\n",
        "    'Tool Wear Failure': {\n",
        "        'Rotational speed [rpm]': 26.353454,\n",
        "        'Torque [Nm]': -7.054300,\n",
        "        'Tool wear [min]': 107.952600\n",
        "    }\n",
        "}\n",
        "\n",
        "# Define groups of failure types\n",
        "grouped_failure_types = {\n",
        "    'Tool Wear Failure and Overstrain Failure': ['Tool Wear Failure', 'Overstrain Failure'],\n",
        "    'Power Failure and Random Failures': ['Power Failure', 'Random Failures'],\n",
        "    'Heat Dissipation Failure': ['Heat Dissipation Failure']\n",
        "}\n",
        "\n",
        "# Plotting mean differences for each group of failure types\n",
        "for group_name, failure_types in grouped_failure_types.items():\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for failure_type in failure_types:\n",
        "        mean_diff_data = new_mean_diff_by_failure_type1[failure_type]\n",
        "        plt.plot(mean_diff_data.keys(), mean_diff_data.values(), label=failure_type)\n",
        "    plt.xlabel('Machine Parameter')\n",
        "    plt.ylabel('Mean Difference')\n",
        "    plt.title(f'Mean Differences of Machine Parameters for x_1 {group_name}')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "1yTXj-juxCWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named 'data'\n",
        "# Filter data for Machine Type 'x1'\n",
        "machine_x1_data = data[data['Machine Type'] == 'x1']\n",
        "\n",
        "# Group data by 'Failure Type'\n",
        "grouped_by_failure = machine_x1_data.groupby('Failure Type')\n",
        "\n",
        "# Extract data for reference groups ('No Failure' and 'Error')\n",
        "reference_groups = ['No Failure', 'Error']\n",
        "reference_data = grouped_by_failure.get_group(reference_groups[0])\n",
        "for group in reference_groups[1:]:\n",
        "    reference_data = reference_data.append(grouped_by_failure.get_group(group))\n",
        "\n",
        "# Selecting the relevant features\n",
        "features_of_interest = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
        "\n",
        "# Initialize a dictionary to store differences for each failure type\n",
        "failure_differences = {}\n",
        "\n",
        "# Loop through each failure type and calculate the differences\n",
        "for failure_type, failure_data in grouped_by_failure:\n",
        "    if failure_type not in reference_groups:\n",
        "        # Calculate the differences between reference groups and the current failure type for selected features\n",
        "        differences = failure_data[features_of_interest].mean() - reference_data[features_of_interest].mean()\n",
        "        # Store the differences in the dictionary\n",
        "        failure_differences[failure_type] = differences\n",
        "\n",
        "# Display the differences for each failure type\n",
        "for failure_type, differences in failure_differences.items():\n",
        "    print(f\"Differences for {failure_type}:\")\n",
        "    print(differences)\n",
        "    print()  # Add a blank line for readability\n"
      ],
      "metadata": {
        "id": "pSlSMmtnFPwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# New mean differences for each failure type\n",
        "new_mean_diff_by_failure_type2 = {\n",
        "    'Heat Dissipation Failure': {\n",
        "        'Rotational speed [rpm]': -191.252161,\n",
        "        'Torque [Nm]': 13.308665,\n",
        "        'Tool wear [min]': 6.729819\n",
        "    },\n",
        "    'Overstrain Failure': {\n",
        "        'Rotational speed [rpm]': -234.085494,\n",
        "        'Torque [Nm]': 19.116998,\n",
        "        'Tool wear [min]': 93.913152\n",
        "    },\n",
        "    'Power Failure': {\n",
        "        'Rotational speed [rpm]': 225.091925,\n",
        "        'Torque [Nm]': 7.703288,\n",
        "        'Tool wear [min]': -8.482009\n",
        "    },\n",
        "    'Random Failures': {\n",
        "        'Rotational speed [rpm]': 5.414506,\n",
        "        'Torque [Nm]': -6.608002,\n",
        "        'Tool wear [min]': 6.663152\n",
        "    },\n",
        "    'Tool Wear Failure': {\n",
        "        'Rotational speed [rpm]': 70.843077,\n",
        "        'Torque [Nm]': -6.815145,\n",
        "        'Tool wear [min]': 111.234581\n",
        "    }\n",
        "}\n",
        "\n",
        "# Define groups of failure types\n",
        "grouped_failure_types = {\n",
        "    'Tool Wear Failure and Overstrain Failure': ['Tool Wear Failure', 'Overstrain Failure'],\n",
        "    'Power Failure and Random Failures': ['Power Failure', 'Random Failures'],\n",
        "    'Heat Dissipation Failure': ['Heat Dissipation Failure']\n",
        "}\n",
        "\n",
        "# Plotting mean differences for each group of failure types\n",
        "for group_name, failure_types in grouped_failure_types.items():\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for failure_type in failure_types:\n",
        "        mean_diff_data = new_mean_diff_by_failure_type2[failure_type]\n",
        "        plt.plot(mean_diff_data.keys(), mean_diff_data.values(), label=failure_type)\n",
        "    plt.xlabel('Machine Parameter')\n",
        "    plt.ylabel('Mean Difference')\n",
        "    plt.title(f'Mean Differences of Machine Parameters for x1 {group_name}')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "svAezQv6yc5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named 'data'\n",
        "# Filter data for Machine Type 'X1'\n",
        "machine_X1_data = data[data['Machine Type'] == 'X1']\n",
        "\n",
        "# Group data by 'Failure Type'\n",
        "grouped_by_failure = machine_X1_data.groupby('Failure Type')\n",
        "\n",
        "# Extract data for reference groups ('No Failure' and 'Error')\n",
        "reference_groups = ['No Failure', 'Error']\n",
        "reference_data = grouped_by_failure.get_group(reference_groups[0])\n",
        "for group in reference_groups[1:]:\n",
        "    reference_data = reference_data.append(grouped_by_failure.get_group(group))\n",
        "\n",
        "# Selecting the relevant features\n",
        "features_of_interest = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
        "\n",
        "# Initialize a dictionary to store differences for each failure type\n",
        "failure_differences = {}\n",
        "\n",
        "# Loop through each failure type and calculate the differences\n",
        "for failure_type, failure_data in grouped_by_failure:\n",
        "    if failure_type not in reference_groups:\n",
        "        # Calculate the differences between reference groups and the current failure type for selected features\n",
        "        differences = failure_data[features_of_interest].mean() - reference_data[features_of_interest].mean()\n",
        "        # Store the differences in the dictionary\n",
        "        failure_differences[failure_type] = differences\n",
        "\n",
        "# Display the differences for each failure type\n",
        "for failure_type, differences in failure_differences.items():\n",
        "    print(f\"Differences for {failure_type}:\")\n",
        "    print(differences)\n",
        "    print()  # Add a blank line for readability\n"
      ],
      "metadata": {
        "id": "GVfDNwXlGN3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mean differences for each failure type\n",
        "heat_dissipation = {\n",
        "    'Air temperature [K]': 3.791813,\n",
        "    'Process temperature [K]': 1.031658,\n",
        "    'Rotational speed [rpm]': -219.116081,\n",
        "    'Torque [Nm]': 11.569728,\n",
        "    'Tool wear [min]': -18.902850\n",
        "}\n",
        "\n",
        "overstrain_failure = {\n",
        "    'Air temperature [K]': 3.891813,\n",
        "    'Process temperature [K]': 2.481658,\n",
        "    'Rotational speed [rpm]': -130.491081,\n",
        "    'Torque [Nm]': 10.232228,\n",
        "    'Tool wear [min]': 139.347150\n",
        "}\n",
        "\n",
        "power_failure = {\n",
        "    'Air temperature [K]': 1.531813,\n",
        "    'Process temperature [K]': 0.241658,\n",
        "    'Rotational speed [rpm]': 40.108919,\n",
        "    'Torque [Nm]': 12.792228,\n",
        "    'Tool wear [min]': 35.147150\n",
        "}\n",
        "\n",
        "random_failures = {\n",
        "    'Air temperature [K]': 1.916813,\n",
        "    'Process temperature [K]': 0.731658,\n",
        "    'Rotational speed [rpm]': -35.741081,\n",
        "    'Torque [Nm]': -2.292772,\n",
        "    'Tool wear [min]': -51.402850\n",
        "}\n",
        "\n",
        "tool_wear_failure = {\n",
        "    'Air temperature [K]': 0.891813,\n",
        "    'Process temperature [K]': -0.601675,\n",
        "    'Rotational speed [rpm]': -49.324414,\n",
        "    'Torque [Nm]': -2.484439,\n",
        "    'Tool wear [min]': 114.180484\n",
        "}\n",
        "\n",
        "# Define groups of failure types\n",
        "grouped_failure_types = {\n",
        "    'Tool Wear Failure and Overstrain Failure': ['mean_diff_tool_wear_failure', 'mean_diff_overstrain_failure'],\n",
        "    'Power Failure and Random Failures': ['mean_diff_power_failure', 'mean_diff_random_failures'],\n",
        "    'Heat Dissipation Failure': ['mean_diff_heat_dissipation']\n",
        "}\n",
        "\n",
        "# Plotting mean differences for each group of failure types\n",
        "for group_name, failure_types in grouped_failure_types.items():\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for failure_type in failure_types:\n",
        "        mean_diff_data = globals()[failure_type]\n",
        "        plt.plot(mean_diff_data.keys(), mean_diff_data.values(), label=failure_type)\n",
        "    plt.xlabel('Machine Parameter')\n",
        "    plt.ylabel('Mean Difference')\n",
        "    plt.title(f'Mean Differences of Machine Parameters for X1 {group_name}')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "7MnAq5MF5G1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mean differences for each failure type\n",
        "heat_dissipation = {\n",
        "    'Rotational speed [rpm]': -219.116081,\n",
        "    'Torque [Nm]': 11.569728,\n",
        "    'Tool wear [min]': -18.902850\n",
        "}\n",
        "\n",
        "overstrain_failure = {\n",
        "    'Rotational speed [rpm]': -130.491081,\n",
        "    'Torque [Nm]': 10.232228,\n",
        "    'Tool wear [min]': 139.347150\n",
        "}\n",
        "\n",
        "power_failure = {\n",
        "    'Rotational speed [rpm]': 40.108919,\n",
        "    'Torque [Nm]': 12.792228,\n",
        "    'Tool wear [min]': 35.147150\n",
        "}\n",
        "\n",
        "random_failures = {\n",
        "    'Rotational speed [rpm]': -35.741081,\n",
        "    'Torque [Nm]': -2.292772,\n",
        "    'Tool wear [min]': -51.402850\n",
        "}\n",
        "\n",
        "tool_wear_failure = {\n",
        "    'Rotational speed [rpm]': -49.324414,\n",
        "    'Torque [Nm]': -2.484439,\n",
        "    'Tool wear [min]': 114.180484\n",
        "}\n",
        "\n",
        "# Define groups of failure types\n",
        "grouped_failure_types = {\n",
        "    'Tool Wear Failure and Overstrain Failure': ['tool_wear_failure', 'overstrain_failure'],\n",
        "    'Power Failure and Random Failures': ['power_failure', 'random_failures'],\n",
        "    'Heat Dissipation Failure': ['heat_dissipation']\n",
        "}\n",
        "\n",
        "# Plotting mean differences for each group of failure types\n",
        "for group_name, failure_types in grouped_failure_types.items():\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for failure_type in failure_types:\n",
        "        mean_diff_data = globals()[failure_type]\n",
        "        plt.plot(mean_diff_data.keys(), mean_diff_data.values(), label=failure_type)\n",
        "    plt.xlabel('Machine Parameter')\n",
        "    plt.ylabel('Mean Difference')\n",
        "    plt.title(f'Mean Differences of Machine Parameters for X1 {group_name}')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "rujp5hY9OWJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mean differences for each failure type\n",
        "mean_diff_heat_dissipation = {\n",
        "    'Air temperature [K]': 3.791813,\n",
        "    'Process temperature [K]': 1.031658,\n",
        "    'Rotational speed [rpm]': -219.116081,\n",
        "    'Torque [Nm]': 11.569728,\n",
        "    'Tool wear [min]': -18.902850\n",
        "}\n",
        "\n",
        "mean_diff_overstrain = {\n",
        "    'Air temperature [K]': 3.891813,\n",
        "    'Process temperature [K]': 2.481658,\n",
        "    'Rotational speed [rpm]': -130.491081,\n",
        "    'Torque [Nm]': 10.232228,\n",
        "    'Tool wear [min]': 139.347150\n",
        "}\n",
        "\n",
        "mean_diff_power_failure = {\n",
        "    'Air temperature [K]': 1.531813,\n",
        "    'Process temperature [K]': 0.241658,\n",
        "    'Rotational speed [rpm]': 40.108919,\n",
        "    'Torque [Nm]': 12.792228,\n",
        "    'Tool wear [min]': 35.147150\n",
        "}\n",
        "\n",
        "mean_diff_random_failures = {\n",
        "    'Air temperature [K]': 1.916813,\n",
        "    'Process temperature [K]': 0.731658,\n",
        "    'Rotational speed [rpm]': -35.741081,\n",
        "    'Torque [Nm]': -2.292772,\n",
        "    'Tool wear [min]': -51.402850\n",
        "}\n",
        "\n",
        "mean_diff_tool_wear_failure = {\n",
        "    'Air temperature [K]': 0.891813,\n",
        "    'Process temperature [K]': -0.601675,\n",
        "    'Rotational speed [rpm]': -49.324414,\n",
        "    'Torque [Nm]': -2.484439,\n",
        "    'Tool wear [min]': 114.180484\n",
        "}\n",
        "\n",
        "# Plotting mean differences over time for each failure type\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot mean differences for Heat Dissipation Failure\n",
        "plt.plot(mean_diff_heat_dissipation.keys(), mean_diff_heat_dissipation.values(), label='Heat Dissipation Failure')\n",
        "\n",
        "# Plot mean differences for Overstrain Failure\n",
        "plt.plot(mean_diff_overstrain.keys(), mean_diff_overstrain.values(), label='Overstrain Failure')\n",
        "\n",
        "# Plot mean differences for Power Failure\n",
        "plt.plot(mean_diff_power_failure.keys(), mean_diff_power_failure.values(), label='Power Failure')\n",
        "\n",
        "# Plot mean differences for Random Failures\n",
        "plt.plot(mean_diff_random_failures.keys(), mean_diff_random_failures.values(), label='Random Failures')\n",
        "\n",
        "# Plot mean differences for Tool Wear Failure\n",
        "plt.plot(mean_diff_tool_wear_failure.keys(), mean_diff_tool_wear_failure.values(), label='Tool Wear Failure')\n",
        "\n",
        "plt.xlabel('Machine Parameter')\n",
        "plt.ylabel('Mean Difference')\n",
        "plt.title('Mean Differences of Machine Parameters for Different Failure Types for X1')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SvqRXgFTGx_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named 'data'\n",
        "# Filter data for Machine Type 'x_2'\n",
        "machine_x_2_data = data[data['Machine Type'] == 'x_2']\n",
        "\n",
        "# Group data by 'Failure Type'\n",
        "grouped_by_failure = machine_x_2_data.groupby('Failure Type')\n",
        "\n",
        "# Initialize a list to store reference groups\n",
        "reference_groups = ['No Failure', 'Error']\n",
        "reference_data = pd.DataFrame()  # Initialize an empty DataFrame\n",
        "\n",
        "# Extract data for reference groups if they exist\n",
        "for group in reference_groups:\n",
        "    if group in grouped_by_failure.groups:\n",
        "        reference_data = reference_data.append(grouped_by_failure.get_group(group))\n",
        "\n",
        "# Selecting the relevant features\n",
        "features_of_interest = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
        "\n",
        "# Initialize a dictionary to store differences for each failure type\n",
        "failure_differences = {}\n",
        "\n",
        "# Check if there are failure types other than the reference groups\n",
        "if len(grouped_by_failure) > len(reference_groups):\n",
        "    # Loop through each failure type and calculate the differences\n",
        "    for failure_type, failure_data in grouped_by_failure:\n",
        "        if failure_type not in reference_groups:\n",
        "            # Calculate the differences between reference groups and the current failure type for selected features\n",
        "            differences = failure_data[features_of_interest].mean() - reference_data[features_of_interest].mean()\n",
        "            # Store the differences in the dictionary\n",
        "            failure_differences[failure_type] = differences\n",
        "\n",
        "    # Display the differences for each failure type\n",
        "    for failure_type, differences in failure_differences.items():\n",
        "        print(f\"Differences for {failure_type}:\")\n",
        "        print(differences)\n",
        "        print()  # Add a blank line for readability\n",
        "else:\n",
        "    print(\"There are no failure types other than the reference groups ('No Failure' and 'Error').\")\n"
      ],
      "metadata": {
        "id": "kYmq9NEr6Y_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mean differences for each failure type\n",
        "heat_dissipation = {\n",
        "    'Rotational speed [rpm]': -219.116081,\n",
        "    'Torque [Nm]': 11.569728,\n",
        "    'Tool wear [min]': -18.902850\n",
        "}\n",
        "\n",
        "overstrain_failure = {\n",
        "    'Rotational speed [rpm]': -130.491081,\n",
        "    'Torque [Nm]': 10.232228,\n",
        "    'Tool wear [min]': 139.347150\n",
        "}\n",
        "\n",
        "power_failure = {\n",
        "    'Rotational speed [rpm]': 40.108919,\n",
        "    'Torque [Nm]': 12.792228,\n",
        "    'Tool wear [min]': 35.147150\n",
        "}\n",
        "\n",
        "random_failures = {\n",
        "    'Rotational speed [rpm]': -35.741081,\n",
        "    'Torque [Nm]': -2.292772,\n",
        "    'Tool wear [min]': -51.402850\n",
        "}\n",
        "\n",
        "tool_wear_failure = {\n",
        "    'Rotational speed [rpm]': -49.324414,\n",
        "    'Torque [Nm]': -2.484439,\n",
        "    'Tool wear [min]': 114.180484\n",
        "}\n",
        "\n",
        "# Define groups of failure types\n",
        "grouped_failure_types = {\n",
        "    'Tool Wear Failure and Overstrain Failure': ['tool_wear_failure', 'overstrain_failure'],\n",
        "    'Power Failure and Random Failures': ['power_failure', 'random_failures'],\n",
        "    'Heat Dissipation Failure': ['heat_dissipation']\n",
        "}\n",
        "\n",
        "# Plotting mean differences for each group of failure types\n",
        "for group_name, failure_types in grouped_failure_types.items():\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for failure_type in failure_types:\n",
        "        mean_diff_data = globals()[failure_type]\n",
        "        plt.plot(mean_diff_data.keys(), mean_diff_data.values(), label=failure_type)\n",
        "    plt.xlabel('Machine Parameter')\n",
        "    plt.ylabel('Mean Difference')\n",
        "    plt.title(f'Mean Differences of Machine Parameters for x_2 {group_name}')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ZpO-Pj006hMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mean differences for each failure type\n",
        "mean_diff_heat_dissipation = {\n",
        "    'Air temperature [K]': 3.791813,\n",
        "    'Process temperature [K]': 1.031658,\n",
        "    'Rotational speed [rpm]': -219.116081,\n",
        "    'Torque [Nm]': 11.569728,\n",
        "    'Tool wear [min]': -18.902850\n",
        "}\n",
        "\n",
        "mean_diff_overstrain = {\n",
        "    'Air temperature [K]': 3.891813,\n",
        "    'Process temperature [K]': 2.481658,\n",
        "    'Rotational speed [rpm]': -130.491081,\n",
        "    'Torque [Nm]': 10.232228,\n",
        "    'Tool wear [min]': 139.347150\n",
        "}\n",
        "\n",
        "mean_diff_power_failure = {\n",
        "    'Air temperature [K]': 1.531813,\n",
        "    'Process temperature [K]': 0.241658,\n",
        "    'Rotational speed [rpm]': 40.108919,\n",
        "    'Torque [Nm]': 12.792228,\n",
        "    'Tool wear [min]': 35.147150\n",
        "}\n",
        "\n",
        "mean_diff_random_failures = {\n",
        "    'Air temperature [K]': 1.916813,\n",
        "    'Process temperature [K]': 0.731658,\n",
        "    'Rotational speed [rpm]': -35.741081,\n",
        "    'Torque [Nm]': -2.292772,\n",
        "    'Tool wear [min]': -51.402850\n",
        "}\n",
        "\n",
        "mean_diff_tool_wear_failure = {\n",
        "    'Air temperature [K]': 0.891813,\n",
        "    'Process temperature [K]': -0.601675,\n",
        "    'Rotational speed [rpm]': -49.324414,\n",
        "    'Torque [Nm]': -2.484439,\n",
        "    'Tool wear [min]': 114.180484\n",
        "}\n",
        "\n",
        "# Plotting mean differences over time for each failure type\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot mean differences for Heat Dissipation Failure\n",
        "plt.plot(mean_diff_heat_dissipation.keys(), mean_diff_heat_dissipation.values(), label='Heat Dissipation Failure')\n",
        "\n",
        "# Plot mean differences for Overstrain Failure\n",
        "plt.plot(mean_diff_overstrain.keys(), mean_diff_overstrain.values(), label='Overstrain Failure')\n",
        "\n",
        "# Plot mean differences for Power Failure\n",
        "plt.plot(mean_diff_power_failure.keys(), mean_diff_power_failure.values(), label='Power Failure')\n",
        "\n",
        "# Plot mean differences for Random Failures\n",
        "plt.plot(mean_diff_random_failures.keys(), mean_diff_random_failures.values(), label='Random Failures')\n",
        "\n",
        "# Plot mean differences for Tool Wear Failure\n",
        "plt.plot(mean_diff_tool_wear_failure.keys(), mean_diff_tool_wear_failure.values(), label='Tool Wear Failure')\n",
        "\n",
        "plt.xlabel('Machine Parameter')\n",
        "plt.ylabel('Mean Difference')\n",
        "plt.title('Mean Differences of Machine Parameters for Different Failure Types for x_2')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "90dr5Pjy624-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Selecting the relevant columns for correlation analysis\n",
        "selected_columns = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
        "\n",
        "# Creating a new DataFrame with only the selected columns\n",
        "selected_data = data[selected_columns]\n",
        "\n",
        "# Calculating the correlation matrix\n",
        "correlation_matrix = selected_data.corr()\n",
        "\n",
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Heatmap of Process Temperature with Other Features')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NWd4I3vLH-GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOMALY ANALYSIS"
      ],
      "metadata": {
        "id": "_xjCjntgtiaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest  # Example anomaly detection technique\n",
        "from sklearn.preprocessing import StandardScaler  # For feature scaling\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Select relevant features for anomaly detection (excluding target for now)\n",
        "sensor_data = data[['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']]\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(sensor_data.isnull().sum())\n",
        "\n",
        "# Handle missing values (example: impute with median)\n",
        "if sensor_data.isnull().sum().any():\n",
        "    sensor_data = sensor_data.fillna(sensor_data.median())\n",
        "\n",
        "# Feature scaling (standardization)\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(sensor_data)\n",
        "\n",
        "# Anomaly detection model (example: Isolation Forest)\n",
        "clf = IsolationForest(contamination=0.01, random_state=42)  # Adjust contamination parameter as needed\n",
        "clf.fit(scaled_data)\n",
        "\n",
        "# Anomaly scores for testing data (optional)\n",
        "anomaly_scores = clf.decision_function(scaled_data)  # For Isolation Forest\n",
        "# Use appropriate method for other anomaly detection techniques\n",
        "\n",
        "# Higher scores indicate a higher anomaly likelihood\n",
        "\n",
        "# Example: Identifying top 10% anomalies based on scores\n",
        "#anomaly_indices = anomaly_scores.argsort()[-int(0.1 * len(anomaly_scores)):]  # Adjust anomaly percentage\n",
        "\n",
        "# Analyze data points with high anomaly scores and corresponding timestamps from the original data\n",
        "\n",
        "# Combine these insights with domain knowledge to assess if they represent genuine machine performance issues\n",
        "# Assuming a threshold of 0.2 (adjust based on your approach)\n",
        "anomaly_indices = np.where(anomaly_scores > 0.23)[0]\n",
        "\n",
        "# Retrieve corresponding data points and timestamps from the original data\n",
        "anomaly_data = data.iloc[anomaly_indices]\n",
        "\n",
        "anomaly_data\n"
      ],
      "metadata": {
        "id": "Yz5yto5ftktd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn import svm\n",
        "\n",
        "# Select relevant features for anomaly detection (excluding target for now)\n",
        "sensor_data = data[['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']]\n",
        "\n",
        "# Handle missing values (example: impute with mean)\n",
        "print(\"Missing values per column:\")\n",
        "print(sensor_data.isnull().sum())\n",
        "\n",
        "if sensor_data.isnull().sum().any():\n",
        "    sensor_data = sensor_data.fillna(sensor_data.mean())\n",
        "\n",
        "# Feature scaling (standardization)\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(sensor_data)\n",
        "\n",
        "# Anomaly Detection with Isolation Forest\n",
        "\n",
        "# Define Isolation Forest model\n",
        "clf_isolation_forest = IsolationForest(contamination=0.01, random_state=42)  # Adjust contamination parameter as needed\n",
        "clf_isolation_forest.fit(scaled_data)\n",
        "\n",
        "# Anomaly scores for Isolation Forest\n",
        "anomaly_scores_isolation_forest = clf_isolation_forest.decision_function(scaled_data)  # For Isolation Forest\n",
        "\n",
        "# Anomaly Detection with One-Class SVM\n",
        "\n",
        "# Define OC-SVM model\n",
        "#clf_one_class_svm = svm.OneClassSVM(nu=0.1, kernel='rbf')  # Adjust nu and kernel parameters as needed\n",
        "#clf_one_class_svm.fit(scaled_data)\n",
        "# ... (existing code for feature selection and missing value imputation)\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(sensor_data)\n",
        "\n",
        "# One-Class SVM model with scaling\n",
        "clf_one_class_svm = svm.OneClassSVM(nu=0.1, kernel='rbf')  # Adjust nu and kernel parameters as needed\n",
        "clf_one_class_svm.fit(scaled_data)\n",
        "\n",
        "anomaly_scores_one_class_svm = clf_one_class_svm.decision_function(scaled_data)\n",
        "\n",
        "\n",
        "# Anomaly scores using decision function (lower scores indicate anomalies)\n",
        "anomaly_scores_one_class_svm = clf_one_class_svm.decision_function(scaled_data)\n",
        "\n",
        "# Anomaly Identification and Interpretation (example using Isolation Forest scores)\n",
        "\n",
        "# Example: Identifying top 10% anomalies based on scores (Isolation Forest)\n",
        "anomaly_indices_isolation_forest = anomaly_scores_isolation_forest.argsort()[-int(0.1 * len(anomaly_scores_isolation_forest)):]  # Adjust anomaly percentage\n"
      ],
      "metadata": {
        "id": "ume2t7GIth7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anomaly_scores_one_class_svm"
      ],
      "metadata": {
        "id": "fuMgeD3HxN-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anomaly_scores_isolation_forest"
      ],
      "metadata": {
        "id": "YOozi6-QxUMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FEATURE SELECTION**"
      ],
      "metadata": {
        "id": "Z8XmA-LopZ-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define relevant features\n",
        "relevant_features = [\"Air temperature [K]\", \"Process temperature [K]\", \"Rotational speed [rpm]\", \"Torque [Nm]\", \"Tool wear [min]\"]\n",
        "\n",
        "# Extract values for successful runs and other instances\n",
        "successful_data = data[data['Failure Type'] == 'No Failure'][relevant_features].values\n",
        "other_data = data[data['Failure Type'] != 'No Failure'][relevant_features].values\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstrap_samples = 1000\n",
        "\n",
        "# Empty dictionaries to store bootstrap sample means\n",
        "bootstrap_means_successful = {feature: [] for feature in relevant_features}\n",
        "bootstrap_means_other = {feature: [] for feature in relevant_features}\n",
        "\n",
        "# Perform bootstrapping for successful runs\n",
        "# Set a random seed (optional) for reproducibility\n",
        "np.random.seed(42)  # Replace 42 with any desired seed value\n",
        "\n",
        "for _ in range(num_bootstrap_samples):\n",
        "    # Generate bootstrap sample for successful runs\n",
        "    bootstrap_sample = successful_data[np.random.choice(len(successful_data), size=len(successful_data), replace=True)]\n",
        "\n",
        "    # Calculate mean of bootstrap sample for each feature\n",
        "    for i, feature in enumerate(relevant_features):\n",
        "        bootstrap_mean = np.mean(bootstrap_sample[:, i])\n",
        "        bootstrap_means_successful[feature].append(bootstrap_mean)\n",
        "\n",
        "# Perform bootstrapping for other instances\n",
        "for _ in range(num_bootstrap_samples):\n",
        "    # Generate bootstrap sample for other instances\n",
        "    bootstrap_sample = other_data[np.random.choice(len(other_data), size=len(other_data), replace=True)]\n",
        "\n",
        "    # Calculate mean of bootstrap sample for each feature\n",
        "    for i, feature in enumerate(relevant_features):\n",
        "        bootstrap_mean = np.mean(bootstrap_sample[:, i])\n",
        "        bootstrap_means_other[feature].append(bootstrap_mean)\n",
        "\n",
        "# Calculate 95% confidence intervals for each feature\n",
        "confidence_intervals_successful = {feature: np.percentile(bootstrap_means_successful[feature], [2.5, 97.5]) for feature in relevant_features}\n",
        "confidence_intervals_other = {feature: np.percentile(bootstrap_means_other[feature], [2.5, 97.5]) for feature in relevant_features}\n",
        "\n",
        "# Print confidence intervals for each feature\n",
        "for feature in relevant_features:\n",
        "    print(f\"95% Confidence Interval for Successful Runs ({feature}):\", confidence_intervals_successful[feature])\n",
        "    print(f\"95% Confidence Interval for Other Instances ({feature}):\", confidence_intervals_other[feature])\n"
      ],
      "metadata": {
        "id": "lobyVv_ZE03k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import numpy as np\n",
        "relevant_features = [\"Rotational speed [rpm]\", \"Torque [Nm]\", \"Tool wear [min]\"]\n",
        "# Define your dataset with failure and no failure groups\n",
        "successful_data = data[data['Failure Type'] == 'No Failure'][relevant_features].values\n",
        "other_data = data[data['Failure Type'] != 'No Failure'][relevant_features].values\n",
        "\n",
        "# Instantiate a dummy classifier (or regressor) as the estimator\n",
        "dummy_estimator = DummyClassifier(strategy='constant', constant=0)\n",
        "\n",
        "# Fit the dummy estimator\n",
        "dummy_estimator.fit(X=np.zeros((len(successful_data), 1)), y=np.zeros(len(successful_data)))\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "successful_data_scaled = scaler.fit_transform(successful_data)\n",
        "other_data_scaled = scaler.transform(other_data)\n",
        "\n",
        "# Calculate permutation importances for each feature\n",
        "perm_importances_successful = permutation_importance(estimator=dummy_estimator, X=successful_data_scaled, y=np.zeros(len(successful_data)), n_repeats=30, random_state=42)\n",
        "perm_importances_other = permutation_importance(estimator=dummy_estimator, X=other_data_scaled, y=np.zeros(len(other_data)), n_repeats=30, random_state=42)\n",
        "\n",
        "# Get mean importances and standard deviations\n",
        "mean_importances_successful = perm_importances_successful.importances_mean\n",
        "mean_importances_other = perm_importances_other.importances_mean\n",
        "\n",
        "# Print mean importances for each feature\n",
        "print(\"Mean Permutation Importances for Successful Runs:\")\n",
        "for feature, importance in zip(relevant_features, mean_importances_successful):\n",
        "    print(f\"{feature}: {importance}\")\n",
        "\n",
        "print(\"\\nMean Permutation Importances for Other Instances:\")\n",
        "for feature, importance in zip(relevant_features, mean_importances_other):\n",
        "    print(f\"{feature}: {importance}\")\n"
      ],
      "metadata": {
        "id": "24-vYGeOPZiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the necessary features (excluding air temperature and process temperature)\n",
        "necessary_features = [\"Rotational speed [rpm]\", \"Torque [Nm]\", \"Tool wear [min]\"]\n",
        "\n",
        "# Select the necessary features and the target variable from the dataset\n",
        "selected_data = data[necessary_features + [\"Target\"]]\n",
        "\n",
        "# Compute the correlation matrix\n",
        "correlation_matrix = selected_data.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", annot_kws={\"size\": 12})\n",
        "plt.title(\"Correlation Matrix Heatmap of Necessary Features vs. Target\", fontsize=16)\n",
        "plt.xlabel(\"Features\", fontsize=14)\n",
        "plt.ylabel(\"Features\", fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "T-TWkaDPTr23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANOMALY DETECTION**"
      ],
      "metadata": {
        "id": "7-k3Lg1ieL5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Exclude non-numeric columns from the dataset\n",
        "numeric_data = data.select_dtypes(include=['float64', 'int64'])  # Assuming numeric columns are of type float64 or int64\n",
        "\n",
        "# Split data into training and testing sets (addressing overfitting)\n",
        "X_train, X_test, _, _ = train_test_split(numeric_data, numeric_data.index, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and fit the Isolation Forest model\n",
        "isolation_forest = IsolationForest(contamination='auto', random_state=42)\n",
        "isolation_forest.fit(X_train)\n",
        "\n",
        "# Predict outliers/anomalies on the testing set (prevents using training data for evaluation)\n",
        "outlier_preds = isolation_forest.predict(X_test)\n",
        "\n",
        "# Identify outliers/anomalies (outlier_preds = -1 indicates an outlier) on the testing set\n",
        "outliers = X_test[outlier_preds == -1]\n",
        "\n",
        "iso_outliers = pd.DataFrame(outliers, columns=numeric_data.columns)\n",
        "\n",
        "# Display the outliers DataFrame for testing set\n",
        "print(\"DataFrame for identified outliers on testing set:\")\n",
        "print(iso_outliers)\n"
      ],
      "metadata": {
        "id": "GNkXXa7pkQ3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iso_0 = iso_outliers[iso_outliers[\"Target\"] == 1].shape[0]\n",
        "iso_0"
      ],
      "metadata": {
        "id": "4_AwYPyzfht5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Exclude non-numeric columns from the dataset\n",
        "numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, _, _ = train_test_split(numeric_data, numeric_data.index, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and fit the LOF model for novelty detection\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination='auto', novelty=True)\n",
        "lof.fit(X_train)\n",
        "\n",
        "# Predict outliers/anomalies on the testing set (unseen data)\n",
        "outlier_preds_lof = lof.predict(X_test)\n",
        "\n",
        "# Identify outliers/anomalies (outlier_preds_lof = -1 indicates an outlier)\n",
        "outliers_lof = X_test[outlier_preds_lof == -1]\n",
        "\n",
        "LOF_outliers = pd.DataFrame(outliers_lof, columns=numeric_data.columns)\n",
        "\n",
        "# Display the outliers DataFrame for testing set\n",
        "print(\"DataFrame for identified outliers on testing set:\")\n",
        "LOF_outliers.info()\n"
      ],
      "metadata": {
        "id": "GQq-PorDnWz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOF_1 = LOF_outliers[LOF_outliers[\"Target\"] == 1].shape[0]\n",
        "LOF_1"
      ],
      "metadata": {
        "id": "h777Ba-Sn_Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your data has a target variable indicating failures (1: failure, 0: normal)\n",
        "data_with_target = data.copy()  # Avoid modifying the original data\n",
        "\n",
        "# Select only numeric features (assuming target variable isn't numeric)\n",
        "numeric_data = data_with_target.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Split data into training and testing sets (considering potential class imbalance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(numeric_data,\n",
        "                                                  data_with_target['Failure'],\n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=42,\n",
        "                                                  stratify=data_with_target['Failure'])\n",
        "\n",
        "from sklearn.svm import OneClassSVM\n",
        "# One-Class SVM for anomaly detection\n",
        "clf = OneClassSVM(nu=0.1, kernel='rbf')  # You can experiment with different parameters\n",
        "clf.fit(X_train)\n",
        "\n",
        "# Predict outliers/anomalies on the testing set\n",
        "outlier_preds_svm = clf.predict(X_test)\n",
        "\n",
        "# Identify outliers/anomalies (outlier_preds_svm = -1 indicates an outlier)\n",
        "outliers_svm = X_test[outlier_preds_svm == -1]\n",
        "\n",
        "SVM_outliers = pd.DataFrame(outliers_svm, columns=numeric_data.columns)\n",
        "\n",
        "# Display the outliers DataFrame for testing set\n",
        "print(\"DataFrame for identified outliers using SVM on testing set:\")\n",
        "SVM_outliers.info()\n",
        "\n"
      ],
      "metadata": {
        "id": "FKVGkNj0ptn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate percentage of target values in the main dataset\n",
        "main_target_percentage = data['Target'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Calculate percentage of target values in the outliers dataset\n",
        "outliers_target_percentage = LOF_outliers['Target'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Print the percentages\n",
        "print(\"Percentage of target values in the main dataset:\")\n",
        "print(main_target_percentage)\n",
        "print(\"\\nPercentage of target values in the outliers dataset:\")\n",
        "print(outliers_target_percentage)"
      ],
      "metadata": {
        "id": "EskQIQ0BgB-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the main dataset to include only instances where the target is 1\n",
        "target_1_main = data[data['Target'] == 1]\n",
        "print(len(target_1_main))\n",
        "\n",
        "# Count the occurrences of target value 1 in the main dataset\n",
        "total_target_1_main = len(target_1_main)\n",
        "\n",
        "# Count the occurrences of target value 1 in the outliers dataset\n",
        "total_target_1_outliers = iso_outliers[LOF_outliers['Target'] == 1]['Target'].count()\n",
        "\n",
        "print(total_target_1_outliers)\n",
        "\n",
        "# Calculate the percentage of target value 1 outliers with respect to the total occurrences of target value 1 in the main dataset\n",
        "percentage_target_1_outliers = (total_target_1_outliers / total_target_1_main) * 100\n",
        "\n",
        "# Print the percentage\n",
        "print(\"Percentage of target value 1 outliers with respect to total occurrences of target value 1 in the main dataset:\", percentage_target_1_outliers)\n"
      ],
      "metadata": {
        "id": "MXCX8P8XgIBu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}